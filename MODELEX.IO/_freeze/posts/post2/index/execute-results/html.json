{
  "hash": "a3e09ff6fad9e31f1968b1c60e5ab724",
  "result": {
    "markdown": "---\ntitle: \"A first look at a neural network\"\nauthor: \" \"\ndate: \"2023-04-27\"\ncategories: [Neural Network, Deep Learning, images classification, handwritten digits, Keras]\n---\n\n\n\n\n***\n\nThis notebook contains the code samples found in Chapter 2, Section 1 of [Deep Learning with R](https://www.manning.com/books/deep-learning-with-r). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n\n***\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(keras)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nc(c(x_train, y_train), c(x_test, y_test)) %<-% keras::dataset_mnist()\n\ncat(\"\\nX train shape:\\t\", dim(x_train))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nX train shape:\t 60000 28 28\n```\n:::\n\n```{.r .cell-code}\ncat(\"\\nX test shape:\\t\", dim(x_test))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nX test shape:\t 10000 28 28\n```\n:::\n\n```{.r .cell-code}\ncat(\"\\nY train shape:\\t\", dim(y_train))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nY train shape:\t 60000\n```\n:::\n\n```{.r .cell-code}\ncat(\"\\nY test shape:\\t\", dim(y_test))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nY test shape:\t 10000\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_digits_by_class <- function(c) {\n  # plot first 15 digits of class c\n\n  # accepted labels are between 0 and 9\n  if (c > -1 & c < 10) {\n\n    # indexes of the first 15 digits of class c\n    idx <- which(y_train == c)[1:15]\n    \n    # prepare plotting area\n    par(mfcol=c(3, 5))\n    par(mar=c(0, 0, 0, 0), xaxs = 'i', yaxs = 'i')\n    \n    # plot digits corresponding to indexes\n    for (i in idx) {\n      img <- x_train[i,,]\n      img <- t(apply(img, 2, rev))\n      image(1:28, 1:28, img, col = gray((0:255) / 255), xaxt = 'n', yaxt = 'n')\n      }\n    } else {\n      return(\"Labels are between 0 and 9.\")\n    }\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nx_train_reshaped = array_reshape(x_train, c(60000, 28*28)) / 255\nx_test_reshaped = array_reshape(x_test, c(10000, 28*28)) / 255\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ny_train <- to_categorical(y_train)\ny_test <- to_categorical(y_test)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- keras_model_sequential(input_shape = c(28 * 28)) %>%\n  layer_dense(units = 512, activation = \"relu\") %>%\n  layer_dropout(0.2) %>%\n  layer_dense(units = 10, activation = \"softmax\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel %>%\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n dense_1 (Dense)                    (None, 512)                     401920      \n dropout (Dropout)                  (None, 512)                     0           \n dense (Dense)                      (None, 10)                      5130        \n================================================================================\nTotal params: 407,050\nTrainable params: 407,050\nNon-trainable params: 0\n________________________________________________________________________________\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel %>% compile(\n  optimizer = \"rmsprop\",\n  loss = \"categorical_crossentropy\",\n  metrics = c(\"accuracy\")\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit the model\nhistory  <- model %>% fit(\n  x_train_reshaped,\n  y_train,\n  epochs = 3,\n  batch_size = 128,\n  validation_split = 0.2\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot training history\nhistory %>% \n  plot() + \n  geom_point(size = 3) + \n  geom_line(linetype = \"dashed\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_metrics <- model %>% \n  evaluate(x_test_reshaped, y_test)\n\ntest_metrics[\"accuracy\"] %>% round(., 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\naccuracy \n   0.974 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# get test set predictions\ny_hat <- model %>%\n  predict(x_test_reshaped) %>% \n  k_argmax() %>%\n  as.array()\n\n# get test set real labels\ny_obs <- y_test %>% \n   k_argmax() %>%\n   as.array()\n\n# get misclassified samples indexes\nmisclass_idx = which(y_hat != y_obs)\n\n# plot 25 misclassified digits\npar(mfcol=c(5, 5))\npar(mar=c(0, 0, 2.5, 0), xaxs = 'i', yaxs = 'i')\n    \nfor (i in misclass_idx[0:25]) {\n      img <- x_test[i,,]\n      img <- t(apply(img, 2, rev))\n      image(1:28, 1:28, img, col = gray((0:255)/255), xaxt = 'n', yaxt = 'n',\n        main = paste(\"Predicted: \", y_hat[i] , \"\\nTrue: \", y_obs[i]))\n}\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}